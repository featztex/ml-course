{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfhMSQLpQjNA"
      },
      "source": [
        "## Домашнее задание №7\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rX_5chsaQjNH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm, tqdm_notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA5vYQI8QjNK"
      },
      "source": [
        "### Задача №1:\n",
        "Обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша основная задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку первого занятия.\n",
        "\n",
        "Настоятельно рекомендуем написать код \"с нуля\", лишь поглядывая на готовые примеры, а не просто \"скопировать-вставить\". Это поможет вам в дальнейшем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R3J2gl-QQjNM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "efd8dc94-5884-42a5-e95e-5561df1a3dc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 240878975.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 56738029.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 137111248.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 8308124.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 1')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f'Image label: {_label}')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pkrJz7EQjNN"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 92% accuracy.\n",
        "\n",
        "*Комментарий: для этого достаточно линейных слоев и функций активации.*\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model`.__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "    DEVICE = torch.device(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aP-0WQbQ9gd",
        "outputId": "8a75c92d-5c28-41bb-924a-07d3334bc069"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is not available.  Training on CPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_epoch(model, train_loader, criterion, optimizer):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_data = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_data += inputs.size(0)\n",
        "\n",
        "    train_loss = running_loss / processed_data\n",
        "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def eval_epoch(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_size = 0\n",
        "\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_size += inputs.size(0)\n",
        "    val_loss = running_loss / processed_size\n",
        "    val_acc = running_corrects.float() / processed_size\n",
        "    return val_loss, val_acc\n",
        "\n",
        "def train(model, epochs, criterion=None, opt=None, scheduler=None):\n",
        "\n",
        "    training_loader = train_data_loader\n",
        "    validation_loader = test_data_loader\n",
        "    history = []\n",
        "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
        "\n",
        "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
        "        if not opt:\n",
        "            opt = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "        if not criterion:\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_loss, train_acc = fit_epoch(model, training_loader, criterion, opt)\n",
        "            if scheduler:\n",
        "                scheduler.step()\n",
        "            #print(\"loss\", train_loss)\n",
        "\n",
        "            val_loss, val_acc = eval_epoch(model, validation_loader, criterion)\n",
        "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
        "\n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
        "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "yDPXR6rHRKBH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ccc99nI7QjNN"
      },
      "outputs": [],
      "source": [
        "features = 784\n",
        "classes = 10\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)\n",
        ").to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Общее число параметров: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MhN1uxbT-Jb",
        "outputId": "e02cb56d-8630-4aa2-ecbb-34a74e507d0a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Общее число параметров: 118282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train(model=model, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNbxRbejSgon",
        "outputId": "d772ca4a-cec7-4951-d0f7-dac17546faf9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  10%|█         | 1/10 [00:21<03:11, 21.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 001 train_loss: 0.4004 val_loss 0.2082 train_acc 0.8907 val_acc 0.9387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  20%|██        | 2/10 [00:43<02:56, 22.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 002 train_loss: 0.1802 val_loss 0.1470 train_acc 0.9470 val_acc 0.9575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  30%|███       | 3/10 [01:06<02:36, 22.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 003 train_loss: 0.1270 val_loss 0.1115 train_acc 0.9631 val_acc 0.9660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  40%|████      | 4/10 [01:28<02:12, 22.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 004 train_loss: 0.0971 val_loss 0.0972 train_acc 0.9707 val_acc 0.9699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  50%|█████     | 5/10 [01:51<01:52, 22.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 005 train_loss: 0.0765 val_loss 0.0849 train_acc 0.9768 val_acc 0.9742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  60%|██████    | 6/10 [02:13<01:29, 22.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 006 train_loss: 0.0621 val_loss 0.0818 train_acc 0.9816 val_acc 0.9753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  70%|███████   | 7/10 [02:36<01:07, 22.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 007 train_loss: 0.0508 val_loss 0.0778 train_acc 0.9846 val_acc 0.9757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  80%|████████  | 8/10 [02:59<00:45, 22.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 008 train_loss: 0.0430 val_loss 0.0747 train_acc 0.9866 val_acc 0.9760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:  90%|█████████ | 9/10 [03:20<00:22, 22.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.0357 val_loss 0.0751 train_acc 0.9888 val_acc 0.9771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 100%|██████████| 10/10 [03:44<00:00, 22.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.0293 val_loss 0.0722 train_acc 0.9912 val_acc 0.9773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vbtyjerQjNO"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "bqrZ_pHMQjNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd1f768-382c-465c-e65e-bfc533a0f838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model is not None, 'Please, use `model` variable to store your model'\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].reshape(-1, 784)\n",
        "    y = random_batch[1]\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model(x)\n",
        "except Exception as e:\n",
        "    print('Something is wrong with the model')\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
        "\n",
        "print('Everything seems fine!')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjBS30E_QjNQ"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Рекомендуем поработать с различными оптимизаторами."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKvqj8uuQjNR"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4iwo9vPQjNR"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPi8bLAuQjNS"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sb78yyyeQjNS"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in train_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "SZ7WevZfQjNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c978d7-7c70-4fec-e968-cb9033e4648e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.99427\n"
          ]
        }
      ],
      "source": [
        "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6GWM8QN8QjNT"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NT50QtNeQjNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ba1887-67e9-4789-e4d8-19daf5be6de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9773\n"
          ]
        }
      ],
      "source": [
        "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj5lTt6rQjNU"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZfYJpcCUQjNV"
      },
      "outputs": [],
      "source": [
        "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
        "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auvZsKYHQjNV"
      },
      "source": [
        "### Сдача задания\n",
        "Загрузите файл `hw07_data_dict.npy` (ссылка есть на странице с заданием) и запустите код ниже для генерации посылки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rXEyOHy0QjNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f214e55c-0b64-440c-b4db-8d2bc1960367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_hw07.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import os\n",
        "import json\n",
        "assert os.path.exists('hw07_data_dict.npy'), 'Please, download `hw07_data_dict.npy` and place it in the working directory'\n",
        "\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels).numpy()\n",
        "    predicted_labels = ','.join([str(x) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "loaded_data_dict = np.load('hw07_data_dict.npy', allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])),\n",
        "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test']))\n",
        "}\n",
        "\n",
        "with open('submission_dict_hw07.json', 'w') as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print('File saved to `submission_dict_hw07.json`')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-2tS06JQjNW"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py3_research",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}